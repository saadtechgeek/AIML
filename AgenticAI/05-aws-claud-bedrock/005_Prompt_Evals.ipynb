{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "# Use Haiku for faster evals\n",
    "#model_id = \"us.anthropic.claude-3-5-haiku-20241022-v1:0\"\n",
    "\n",
    "session = boto3.Session(profile_name=\"bedrock-dev\")\n",
    "client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "\n",
    "# Claude model ID â€” must be correct and available in the region\n",
    "model_id = \"us.anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": [{\"text\": text}]}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": [{\"text\": text}]}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"modelId\": model_id,\n",
    "        \"messages\": messages,\n",
    "        \"inferenceConfig\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"stopSequences\": stop_sequences,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = [{\"text\": system}]\n",
    "\n",
    "    response = client.converse(**params)\n",
    "\n",
    "    return response[\"output\"][\"message\"][\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generate_dataset()\n",
    "with open(\"dataset2.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(test_case):\n",
    "    \"\"\" Merges the prompt and test case input, then returns the result\"\"\"\n",
    "    prompt =f\"\"\"\n",
    "    Please solve the following task\n",
    "    {test_case[\"task\"]}\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    output = chat(messages)\n",
    "    return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each of our data values are our test cases\n",
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Criteria you should use to evaluate the solution:\n",
    "<criteria>\n",
    "{test_case[\"solution_criteria\"]}\n",
    "</criteria>\n",
    "\n",
    "Output Format\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths\n",
    "- \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "- \"reasoning\": A concise explanation of your overall assessment\n",
    "- \"score\": A number between 1-10\n",
    "\n",
    "Respond with JSON. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": string[],\n",
    "    \"weaknesses\": string[],\n",
    "    \"reasoning\": string,\n",
    "    \"score\": number\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_case(test_case):\n",
    "    \"\"\"  Calls run_prompt, then grades the result\"\"\"\n",
    "    # goal is take individual cases, call prompt function and grade result describing everyting happen there\n",
    "    output = run_prompt(test_case)\n",
    "    \n",
    "    # TODO - grading\n",
    "    #score = 10\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "    \n",
    "    return {\n",
    "        \"output\" : output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    # this funciton load data set, recieve as argument, loop to data set, and call testcase and assumble\n",
    "    # all test case together\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'solution_criteria'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset2.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 9\u001b[0m, in \u001b[0;36mrun_eval\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      6\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_case \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m----> 9\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_test_case\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Cell \u001b[1;32mIn[30], line 8\u001b[0m, in \u001b[0;36mrun_test_case\u001b[1;34m(test_case)\u001b[0m\n\u001b[0;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m run_prompt(test_case)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# TODO - grading\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#score = 10\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model_grade \u001b[38;5;241m=\u001b[39m \u001b[43mgrade_by_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m score \u001b[38;5;241m=\u001b[39m model_grade[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m reasoning \u001b[38;5;241m=\u001b[39m model_grade[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[1;32mIn[25], line 18\u001b[0m, in \u001b[0;36mgrade_by_model\u001b[1;34m(test_case, output)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgrade_by_model\u001b[39m(test_case, output):\n\u001b[0;32m      3\u001b[0m     eval_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mYou are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\u001b[39m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;124mOriginal Task:\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m<task>\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mtest_case[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m</task>\u001b[39m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124mSolution to Evaluate:\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m<solution>\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m</solution>\u001b[39m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;124mCriteria you should use to evaluate the solution:\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m<criteria>\u001b[39m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtest_case\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msolution_criteria\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124m</criteria>\u001b[39m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;124mOutput Format\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124mProvide your evaluation as a structured JSON object with the following fields, in this specific order:\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m- \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrengths\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: An array of 1-3 key strengths\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124m- \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweaknesses\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: An array of 1-3 key areas for improvement\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m- \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: A concise explanation of your overall assessment\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m- \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: A number between 1-10\u001b[39m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;124mRespond with JSON. Keep your response concise and direct.\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124mExample response shape:\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;130;01m{{\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrengths\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: string[],\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweaknesses\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: string[],\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: string,\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: number\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;130;01m}}\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     38\u001b[0m     messages \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     39\u001b[0m     add_user_message(messages, eval_prompt)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'solution_criteria'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# open json file.\n",
    "with open(\"dataset2.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"output\": \"Here's a Python function that checks if an AWS S3 bucket name is valid according to the AWS naming conventions:\\n\\n```python\\nimport re\\n\\ndef is_valid_bucket_name(bucket_name):\\n    \\\"\\\"\\\"\\n    Checks if a given bucket name is valid according to AWS S3 naming conventions.\\n    \\n    Rules:\\n    - Bucket names must be between 3 and 63 characters long.\\n    - Bucket names can consist only of lowercase letters, numbers, and hyphens.\\n    - Bucket names must start and end with a letter or number.\\n    - Bucket names must not contain consecutive periods or start or end with a period.\\n    - Bucket names must not be formatted as an IP address (e.g., 192.168.5.4).\\n    \\n    Args:\\n        bucket_name (str): The bucket name to be validated.\\n        \\n    Returns:\\n        bool: True if the bucket name is valid, False otherwise.\\n    \\\"\\\"\\\"\\n    # Check length\\n    if len(bucket_name) < 3 or len(bucket_name) > 63:\\n        return False\\n    \\n    # Check characters\\n    if not re.match(r'^[a-z0-9\\\\-]+$', bucket_name):\\n        return False\\n    \\n    # Check start and end characters\\n    if not re.match(r'^[a-z0-9]', bucket_name) or not re.match(r'[a-z0-9]$', bucket_name):\\n        return False\\n    \\n    # Check for consecutive periods\\n    if '..' in bucket_name:\\n        return False\\n    \\n    # Check for IP address format\\n    ip_pattern = r'^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$'\\n    if re.match(ip_pattern, bucket_name):\\n        return False\\n    \\n    return True\\n```\\n\\nHere's how the function works:\\n\\n1. The function first checks if the length of the bucket name is between 3 and 63 characters.\\n2. It then checks if the bucket name consists only of lowercase letters, numbers, and hyphens using a regular expression.\\n3. The function checks if the bucket name starts and ends with a letter or number using regular expressions.\\n4. It checks if the bucket name contains consecutive periods.\\n5. Finally, the function checks if the bucket name is formatted as an IP address using a regular expression.\\n\\nIf any of the above conditions are not met, the function returns `False`. If all conditions are met, it returns `True`.\\n\\nYou can use the function like this:\\n\\n```python\\nprint(is_valid_bucket_name(\\\"mybucket\\\"))  # True\\nprint(is_valid_bucket_name(\\\"my-bucket\\\"))  # True\\nprint(is_valid_bucket_name(\\\"my-bucket-123\\\"))  # True\\nprint(is_valid_bucket_name(\\\"192.168.5.4\\\"))  # False\\nprint(is_valid_bucket_name(\\\"my..bucket\\\"))  # False\\nprint(is_valid_bucket_name(\\\"my_bucket\\\"))  # False\\nprint(is_valid_bucket_name(\\\"my-bucket-name-is-too-long-and-exceeds-63-characters\\\"))  # False\\n```\\n\\nNote that this function only checks if the bucket name adheres to the AWS S3 naming conventions. It does not check if the bucket actually exists or if you have permission to access it.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a Python function that takes an AWS S3 bucket name as input and returns True if the bucket name is valid according to AWS naming conventions, and False otherwise.\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a JSON object representing the configuration for an AWS Lambda function that processes incoming S3 events and logs the bucket name and object key:\\n\\n```json\\n{\\n  \\\"FunctionName\\\": \\\"S3EventProcessor\\\",\\n  \\\"Description\\\": \\\"Processes incoming S3 events and logs the bucket name and object key.\\\",\\n  \\\"Runtime\\\": \\\"nodejs16.x\\\",\\n  \\\"Handler\\\": \\\"index.handler\\\",\\n  \\\"Role\\\": \\\"arn:aws:iam::<YOUR_AWS_ACCOUNT_ID>:role/LambdaS3Role\\\",\\n  \\\"Code\\\": {\\n    \\\"S3Bucket\\\": \\\"<YOUR_S3_BUCKET_NAME>\\\",\\n    \\\"S3Key\\\": \\\"lambda-deployment-packages/s3-event-processor.zip\\\"\\n  },\\n  \\\"Timeout\\\": 10,\\n  \\\"MemorySize\\\": 128,\\n  \\\"Tracing\\\": \\\"Active\\\",\\n  \\\"Environment\\\": {\\n    \\\"Variables\\\": {\\n      \\\"LOG_LEVEL\\\": \\\"INFO\\\"\\n    }\\n  },\\n  \\\"EventInvokeConfig\\\": {\\n    \\\"DestinationConfig\\\": {\\n      \\\"OnSuccess\\\": {\\n        \\\"Type\\\": \\\"SQS\\\",\\n        \\\"Destination\\\": \\\"arn:aws:sqs:<YOUR_AWS_REGION>:<YOUR_AWS_ACCOUNT_ID>:<YOUR_SQS_QUEUE_NAME>\\\"\\n      },\\n      \\\"OnFailure\\\": {\\n        \\\"Type\\\": \\\"SNS\\\",\\n        \\\"Destination\\\": \\\"arn:aws:sns:<YOUR_AWS_REGION>:<YOUR_AWS_ACCOUNT_ID>:<YOUR_SNS_TOPIC_NAME>\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nHere's an explanation of the configuration properties:\\n\\n- `FunctionName`: The name of the Lambda function.\\n- `Description`: A description of the Lambda function.\\n- `Runtime`: The runtime environment for the Lambda function (in this case, Node.js 16.x).\\n- `Handler`: The entry point for the Lambda function (e.g., `index.handler` for a function defined in `index.js` with an exported function named `handler`).\\n- `Role`: The Amazon Resource Name (ARN) of the IAM role that provides permissions for the Lambda function to access other AWS resources.\\n- `Code`: The location of the deployment package for the Lambda function (in this case, an S3 bucket and object key).\\n- `Timeout`: The maximum execution time for the Lambda function (in seconds).\\n- `MemorySize`: The amount of memory allocated to the Lambda function (in MB).\\n- `Tracing`: Enables AWS X-Ray tracing for the Lambda function.\\n- `Environment`: Environment variables for the Lambda function.\\n- `EventInvokeConfig`: Configuration for asynchronous invocation, specifying destinations for successful and failed invocations (e.g., SQS queue for successful invocations, SNS topic for failed invocations).\\n\\nNote: Replace the placeholders (`<YOUR_AWS_ACCOUNT_ID>`, `<YOUR_S3_BUCKET_NAME>`, `<YOUR_AWS_REGION>`, `<YOUR_SQS_QUEUE_NAME>`, and `<YOUR_SNS_TOPIC_NAME>`) with your actual AWS account ID, S3 bucket name, AWS region, SQS queue name, and SNS topic name, respectively.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a JSON object representing the configuration for an AWS Lambda function that processes incoming S3 events and logs the bucket name and object key.\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"To match AWS Resource Names (ARNs) for EC2 instances in a specific region (e.g., us-west-2), you can use the following regular expression in Python:\\n\\n```python\\nimport re\\n\\nregion = \\\"us-west-2\\\"\\narn_pattern = rf\\\"^arn:aws:ec2:{region}:\\\\d+:instance/i-[a-f0-9]+$\\\"\\n\\nsample_arn = \\\"arn:aws:ec2:us-west-2:123456789012:instance/i-0abcdef1234567\\\"\\nmatch = re.match(arn_pattern, sample_arn)\\n\\nif match:\\n    print(\\\"Match found!\\\")\\nelse:\\n    print(\\\"No match found.\\\")\\n```\\n\\nHere's a breakdown of the regular expression pattern:\\n\\n- `^` and `$`: These anchors ensure that the entire string matches the pattern.\\n- `arn:aws:ec2:`: This is a fixed prefix for EC2 instance ARNs.\\n- `{region}`: This is a Python f-string placeholder that inserts the specified region (e.g., `us-west-2`).\\n- `\\\\d+`: This matches one or more digits, representing the AWS account ID.\\n- `:instance/i-`: This is a fixed pattern for EC2 instance ARNs, including the resource type (`instance`) and the prefix `i-`.\\n- `[a-f0-9]+`: This matches one or more hexadecimal characters (a-f, 0-9), representing the instance ID.\\n\\nNote that this regular expression assumes that the ARN follows the standard format for EC2 instances. If you need to match ARNs for other AWS resources or with different formats, you'll need to modify the pattern accordingly.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a regular expression that matches AWS Resource Names (ARNs) for EC2 instances in a specific region (e.g., us-west-2).\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
